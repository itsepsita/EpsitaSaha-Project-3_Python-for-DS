# Importing libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import pickle

# Load the dataset
data = pd.read_csv("loan_approval_data.csv")

# Preview the data
print(data.head())
print("\nShape of data:", data.shape)
print("\nData info:\n", data.info())

### Data Preprocessing
# Handling missing values
data.fillna(data.median(numeric_only=True), inplace=True)
data.fillna("Unknown", inplace=True)

# Drop unnecessary columns (if any, e.g., Loan_ID)
data.drop(columns=['Loan_ID'], inplace=True)

# Encoding categorical variables
categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']
encoder = LabelEncoder()
for col in categorical_columns:
    data[col] = encoder.fit_transform(data[col])

# Splitting data into features (X) and target (y)
X = data.drop(columns=['Loan_Status'])
y = data['Loan_Status']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

### Model Building
# Using Random Forest Classifier
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Model evaluation
y_pred = model.predict(X_test)
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Save the model using pickle
with open('model/loan_model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Save the scaler as well
with open('model/scaler.pkl', 'wb') as file:
    pickle.dump(scaler, file)

print("\nModel and scaler saved successfully!")
